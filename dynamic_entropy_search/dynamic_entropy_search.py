import pickle
from pathlib import Path

import numpy as np
from .dynamic_entropy_search_core import DynamicEntropySearchCore
from .dynamic_with_flash import DynamicWithFlash
from ms_entropy import clean_spectrum


class DynamicEntropySearch:
    def __init__(
        self,
        path_data,
        max_ms2_tolerance_in_da=0.024,
        extend_fold=3,
        mass_per_block: float = 0.05,
        num_per_group: int = 100_000_000,
        cache_list_threshold: int = 1_000_000,
        max_indexed_mz: float = 1500.00005,
        intensity_weight="entropy",  # "entropy" or None
    ):
        """
        Initialize the EntropySearch class.
        Create necessary folder.
        If library exists, read the information.

        :param path_data: The path of the index files.
        :param max_ms2_tolerance_in_da: The maximum MS2 tolerance used when searching the MS/MS spectra, in Dalton. Default is 0.024.
        :param extend_fold: Extension multiple of reserved_len over data_len in each block.
        :param mass_per_block:   The step size of the m/z index, in Dalton. Default is 0.05.
                                The smaller the step size, the faster the search, but the larger the index size and longer the index building time.
        :param num_per_group:  The number of spectra in each group.
        :param cache_list_threshold:    The number of spectra processed in cache_lilst each time.
        :param max_indexed_mz:  The max m/z for indexing. All ions with larger m/z than it will be classified in a single block. Default is 1500.00005.
        :param intensity_weight: The weight of the intensity, can be "entropy" or None. If set to "entropy", the intensity will be weighted by the entropy.
                                If set to None, the intensity will not be weighted, which is equivalent to the unweighted entropy similarity.

        """
        assert cache_list_threshold<=num_per_group, "Cache_list_threshold shouldn't be larger than num_per_group."
        self.path_data = Path(path_data)
        self.num_per_group = num_per_group

        self.max_ms2_tolerance_in_da = max_ms2_tolerance_in_da
        self.extend_fold = extend_fold
        self.mass_per_block = mass_per_block
        self.max_indexed_mz = max_indexed_mz
        self.intensity_weight = intensity_weight

        self.path_data.mkdir(parents=True, exist_ok=True)
        self.cache_list_threshold = cache_list_threshold
        self.cache_list = []
        group_start_path = self.path_data / "group_start.pkl"
        metadata_start_loc_path = self.path_data / "metadata_start_loc.bin"
        if group_start_path.exists() and metadata_start_loc_path.exists():
            self.read()
        else:
            self.group_start = [
                0,
            ]
            self.metadata_start_loc = [
                0,
            ]

        max_group_number = len(self.group_start) - 1
        group_path = self.path_data / f"{max_group_number}"
        self.entropy_search = DynamicEntropySearchCore(
            path_data=group_path,
            max_ms2_tolerance_in_da=self.max_ms2_tolerance_in_da,
            extend_fold=self.extend_fold,
            mass_per_block=self.mass_per_block,
            max_indexed_mz=self.max_indexed_mz,
            intensity_weight=self.intensity_weight,
        )

        self.entropy_search.read()

    def add_new_spectra(self, spectra_list: list, insert_mode="fast_update", index_for_neutral_loss: bool = True, convert_to_flash:bool=True):
        """
        For any spectra to add into the index, use this function.
        :param spectra_list:    spectra list with single ion_mode state generated by function in external.
        :param insert_mode: The mode of insertion, can be "fast_search" or "fast_update". Default is "fast_update".
        """

        metadata_array = []
        # Convert metadata of every spectrum to pkl
        for spec in spectra_list:
            metadata_array.append(pickle.dumps(spec))

        metadata_start_loc_path = self.path_data / "metadata_start_loc.bin"
        if metadata_start_loc_path.exists():
            self.metadata_start_loc = np.memmap(metadata_start_loc_path, mode="r", dtype=np.uint64)

        start_loc = [self.metadata_start_loc[-1]]
        if start_loc == [
            0,
        ]:
            metadata_len = np.cumsum(start_loc + [len(metadata) for metadata in metadata_array]).astype(np.uint64)
        else:
            metadata_len = np.cumsum(start_loc + [len(metadata) for metadata in metadata_array]).astype(np.uint64)[1:]

        with open(self.path_data / "metadata_start_loc.bin", "ab") as f:
            metadata_len.tofile(f)

        # Concatenate them
        metadata_all = b"".join(metadata_array)

        # Save the metadata to file
        metadata_path = self.path_data / "metadata.pkl"

        with open(metadata_path, "ab") as f:
            f.write(metadata_all)

        # Move spectra to cache_list
        self.cache_list.extend(spectra_list)

        # Use spectra in cache_list to build index based on the number of spectra in cache_list
        while len(self.cache_list) >= self.cache_list_threshold:

            self.build_index(insert_mode=insert_mode, index_for_neutral_loss=index_for_neutral_loss, convert_to_flash=convert_to_flash)

        return

    def build_index(self, insert_mode="fast_update", index_for_neutral_loss: bool = True, convert_to_flash:bool=True):
        """
        Perform index building finally.
        This function can also be used in function `add_new_spectra` internally.
        """
        if len(self.cache_list) >= self.cache_list_threshold:
            spectra_to_build = self.cache_list[: self.cache_list_threshold]
            self.cache_list = self.cache_list[self.cache_list_threshold :]

        else:
            if len(self.cache_list) == 0:
                self.entropy_search.write()
                return
            spectra_to_build = self.cache_list
            self.cache_list = []

        # Option 1: if total_spectra_num < self.num_per_group: Insert into an existing group directly
        # Option 2: if total_spectra_num >= self.num_per_group: Create a new group
        # Option 3: if total_spectra_num ==0: build index directly

        # Insert
        if 0 < self.entropy_search.total_spectra_num < self.num_per_group:
            if insert_mode == "fast_update":
                self.entropy_search.fast_add_new_spectrum_into_index(
                    add_spectrum_list=spectra_to_build,
                )

            elif insert_mode == "fast_search":
                # If change to fast_search after fast_update, use `self.convert_to_fast_search()`.
                self.entropy_search.add_new_spectrum_into_index(
                    add_spectrum_list=spectra_to_build,
                )

        # Build directly
        elif self.entropy_search.total_spectra_num == 0:
            self.entropy_search.build_index(all_spectra_list=spectra_to_build, index_for_neutral_loss=index_for_neutral_loss)

        # Create a new class, build de novo
        elif self.entropy_search.total_spectra_num >= self.num_per_group:
            if convert_to_flash:
                # Convert current index to Flash Entropy Search index
                self.entropy_search.convert_to_fast_search()
                self.convert_current_index_to_flash()
            else:
                self.entropy_search.write()

            # Update self.group_start
            self.group_start.append(self.group_start[-1] + self.entropy_search.total_spectra_num)
            max_group_number = len(self.group_start) - 1
            group_path = self.path_data / f"{max_group_number}"
            self.entropy_search = DynamicEntropySearchCore(
                path_data=group_path,
                max_ms2_tolerance_in_da=self.max_ms2_tolerance_in_da,
                extend_fold=self.extend_fold,
                mass_per_block=self.mass_per_block,
                max_indexed_mz=self.max_indexed_mz,
                intensity_weight=self.intensity_weight,
            )

            self.entropy_search.build_index(all_spectra_list=spectra_to_build, index_for_neutral_loss=index_for_neutral_loss)

        # Record precursor_mz
        precursor_mz_array = np.array([spec["precursor_mz"] for spec in spectra_to_build], dtype=np.float32)
        max_group_number = len(self.group_start) - 1
        group_path = self.path_data / f"{max_group_number}"
        with open(group_path / "precursor_mz_array.bin", "ab") as f:
            precursor_mz_array.tofile(f)

        return

    def write(
        self,
    ):
        """
        Write the information to file.

        """
        # Write the information of self.entropy_search
        self.entropy_search.write()

        # Write the information of self.group_start and self.metadata_start_loc
        with open(self.path_data / "group_start.pkl", "wb") as f:
            pickle.dump(self.group_start, f)

        return

    def read(
        self,
    ):
        """
        Read the information from file.
        """
        file_name_group = self.path_data / "group_start.pkl"
        file_name_metadata = self.path_data / "metadata_start_loc.bin"

        with open(file_name_group, "rb") as f:
            self.group_start = pickle.load(f)

        self.metadata_start_loc = np.memmap(file_name_metadata, mode="r", dtype=np.uint64)
        return

    def __getitem__(self, index):
        """
        Get the metadata of result by the group_idx and spec_idx.

        :param index: The glocal spec_idx in the whole library, can be calculated from self.group_start and spec_idx in one group.

        :return: The spectrum with metadata.
        """
        metadata_path = self.path_data / "metadata.pkl"
        self.read()
        with open(metadata_path, "rb") as f:
            f.seek(self.metadata_start_loc[index])
            data = f.read(self.metadata_start_loc[index + 1] - self.metadata_start_loc[index])
            spectrum = pickle.loads(data)

        return spectrum

    def get_metadata(self, group_idx, spec_idx):
        """
        Get the metadata of one spectrum.

        :param group_idx: The corresponding element of self.group_start, which means the number of the first spectrum in this group.
                            e.g. For group 0, it starts with the spec_idx 0 in the whole library;
                            for group 2, it starts with the spec_idx 1000000 in the whole library because group 0 has 1000000 spectra (spec_idx 0-999999) in it.

        :param spec_idx:    The spec_idx in one group, regardless of the whole library.The sum of group_idx and spec_idx is the global spec_idx in the whole library.

        :return: metadata of spectrum

        """
        self.read()
        global_spec_idx = self.group_start[group_idx] + spec_idx
        items = self[global_spec_idx]

        return items

    def identity_search(
        self,
        precursor_mz,
        peaks,
        ms1_tolerance_in_da,
        ms2_tolerance_in_da,
    ):
        """
        Perform identity search in the library under self.path_data.

        :param precursor_mz:    The precursor m/z of the query spectrum.
        :param peaks:   The peaks of the query spectrum, should be cleaned before search.
        :param ms1_tolerance_in_da: The MS1 tolerance in Da.
        :param ms2_tolerance_in_da: The MS2 tolerance in Da.

        :return:    The entropy similarity score for each spectrum in the library, a numpy array with shape (N,), N is the number of spectra in the library.

        """

        all_result = []
        for group in range(len(self.group_start)):
            group_path = self.path_data / f"{group}"
            precursor_mz_file = group_path / "precursor_mz_array.bin"

            if precursor_mz_file.exists():
                precursor_mz_array = np.memmap(precursor_mz_file, mode="r", dtype=np.float32)
                spec_idx = np.where(abs(precursor_mz_array - precursor_mz) <= ms1_tolerance_in_da)[0]
            else:
                raise RuntimeError("Precursor_mz_array not loaded. Call add_new_spectra(...) first. ")
            
            entropy_search=self._assign_entropy_search(group_path=group_path)
                
            cur_result=np.zeros(entropy_search.total_spectra_num, dtype=np.float32)
            cur_result[spec_idx] = entropy_search.search(method="open", peaks=peaks, ms2_tolerance_in_da=ms2_tolerance_in_da)[spec_idx]
            all_result.append(cur_result)
            
        identity_result = np.concatenate(all_result)

        return identity_result

    def open_search(
        self,
        peaks,
        ms2_tolerance_in_da,
    ):
        """
        Perform open search in the library under self.path_data.

        :param peaks:   The peaks of the query spectrum, should be cleaned before search.
        :param ms2_tolerance_in_da: The MS2 tolerance in Da.

        :return:    The entropy similarity score for each spectrum in the library, a numpy array with shape (N,), N is the number of spectra in the library.

        """
        result = []
        # Go through all groups in this library
        for group in range(len(self.group_start)):
            group_path = self.path_data / f"{group}"
            
            entropy_search=self._assign_entropy_search(group_path=group_path)
            
            cur_result = entropy_search.search(method="open", peaks=peaks, ms2_tolerance_in_da=ms2_tolerance_in_da)
            result.append(cur_result)

        open_result = np.concatenate(result)
        return open_result

    def neutral_loss_search(self, precursor_mz, peaks, ms2_tolerance_in_da):
        """
        Perform neutral loss search in the library under self.path_data.

        :param precursor_mz:    The precursor m/z of the query spectrum.
        :param peaks:   The peaks of the query spectrum, should be cleaned before search.
        :param ms2_tolerance_in_da: The MS2 tolerance in Da.

        :return:    The entropy similarity score for each spectrum in the library, a numpy array with shape (N,), N is the number of spectra in the library.

        """

        result = []
        # Go through all groups in this library
        for group in range(len(self.group_start)):
            group_path = self.path_data / f"{group}"

            entropy_search=self._assign_entropy_search(group_path=group_path)
                
            cur_result = entropy_search.search(method="neutral_loss", precursor_mz=precursor_mz, peaks=peaks, ms2_tolerance_in_da=ms2_tolerance_in_da)
            result.append(cur_result)

        neutral_result = np.concatenate(result)

        return neutral_result

    def hybrid_search(self, precursor_mz, peaks, ms2_tolerance_in_da):
        """
        Perform hybrid search in the library under self.path_data.

        :param precursor_mz:    The precursor m/z of the query spectrum.
        :param peaks:   The peaks of the query spectrum, should be cleaned before search.
        :param ms2_tolerance_in_da: The MS2 tolerance in Da.

        :return:    The entropy similarity score for each spectrum in the library, a numpy array with shape (N,), N is the number of spectra in the library.

        """
        result = []
        # Go through all groups in this library
        for group in range(len(self.group_start)):
            group_path = self.path_data / f"{group}"

            entropy_search=self._assign_entropy_search(group_path=group_path)

            cur_result = entropy_search.search_hybrid(precursor_mz=precursor_mz, peaks=peaks, ms2_tolerance_in_da=ms2_tolerance_in_da)
            result.append(cur_result)

        hybrid_result = np.concatenate(result)

        return hybrid_result

    def search(
        self,
        precursor_mz,
        peaks,
        ms1_tolerance_in_da=0.01,
        ms2_tolerance_in_da=0.02,
        method="all",
        precursor_ions_removal_da: float = 1.6,
        clean=True,
        noise_threshold=0.01,
        min_ms2_difference_in_da=0.05,
        max_peak_num=None,
    ):
        """
        Perform Dynamic entropy search for the query spectrum, including cleaning spectrum.

        :param precursor_mz:    The precursor m/z of the query spectrum.
        :param peaks:           The peaks of the query spectrum, should be a list or numpy array with shape (N, 2), N is the number of peaks. The format of the peaks is [[mz1, intensity1], [mz2, intensity2], ...].
        :param ms1_tolerance_in_da:  The MS1 tolerance in Da. Default is 0.01.
        :param ms2_tolerance_in_da:  The MS2 tolerance in Da. Default is 0.02.
        :param method:  The search method, can be "identity", "open", "neutral_loss", "hybrid", "all", or list of the above.
        :param precursor_ions_removal_da:   The ions with m/z larger than precursor_mz - precursor_ions_removal_da will be removed.
                                            Default is 1.6.
        :param noise_threshold: The intensity threshold for removing the noise peaks. The peaks with intensity smaller than noise_threshold * max(intensity)
                                will be removed. Default is 0.01.
        :param min_ms2_difference_in_da:    The minimum difference between two peaks in the MS/MS spectrum. Default is 0.05.
        :param max_peak_num:    The maximum number of peaks in the MS/MS spectrum. Default is None, which means no limit.

        :return:    A dictionary with the search results. The keys are "identity_search", "open_search", "neutral_loss_search", "hybrid_search", and the values are the search results for each method.
        """
        # Assign max_mz
        if precursor_ions_removal_da is not None:
            max_mz = precursor_mz - precursor_ions_removal_da

        else:
            max_mz = -1

        # Clean the query peaks
        if clean:
            peaks = clean_spectrum(
                peaks=peaks,
                min_mz=0,
                max_mz=max_mz,
                noise_threshold=noise_threshold,
                min_ms2_difference_in_da=min_ms2_difference_in_da,
                max_peak_num=max_peak_num,
                normalize_intensity=True,
            )

        # Parse method
        if method == "all":
            method = {"identity", "open", "neutral_loss", "hybrid"}

        elif isinstance(method, str):
            method = {method}

        # Perform search
        result = {}
        if "identity" in method:
            result["identity_search"] = self.identity_search(
                precursor_mz=precursor_mz, peaks=peaks, ms1_tolerance_in_da=ms1_tolerance_in_da, ms2_tolerance_in_da=ms2_tolerance_in_da
            )
        
        if "open" in method:
            result["open_search"] = self.open_search(peaks=peaks, ms2_tolerance_in_da=ms2_tolerance_in_da)
        
        if "neutral_loss" in method:
            result["neutral_loss_search"] = self.neutral_loss_search(
                precursor_mz=precursor_mz, peaks=peaks, ms2_tolerance_in_da=ms2_tolerance_in_da
            )
        
        if "hybrid" in method:
            result["hybrid_search"] = self.hybrid_search(
                precursor_mz=precursor_mz, peaks=peaks, ms2_tolerance_in_da=ms2_tolerance_in_da
            )

        return result

    def search_topn_matches(
        self,
        peaks,
        precursor_mz=None,
        ms1_tolerance_in_da=0.01,
        ms2_tolerance_in_da=0.02,
        method="open",
        clean=True,
        precursor_ions_removal_da: float = 1.6,
        noise_threshold=0.01,
        min_ms2_difference_in_da=0.05,
        max_peak_num=None,
        topn: np.uint64 = 3,
        need_metadata: bool = True,
    ):
        """
        Perform search and get selected results based on the similarity.
        :param peaks:           The peaks of the query spectrum, should be a list or numpy array with shape (N, 2), N is the number of peaks. The format of the peaks is [[mz1, intensity1], [mz2, intensity2], ...].
        :param precursor_mz:    The precursor m/z of the query spectrum.
        :param ms1_tolerance_in_da:  The MS1 tolerance in Da. Default is 0.01.
        :param ms2_tolerance_in_da:  The MS2 tolerance in Da. Default is 0.02.
        :param method:  The search method, can be "identity", "open", "neutral_loss" or "hybrid".
        :param topn:    The number of MS/MS spectra to return, if None, all the MS/MS spectra will be returned.
        :param need_metadata:   If it is True, the metadata of spectra will be returned.

        :return:    The topn MS/MS spectra with the highest entropy similarity.

        """
        all_topn_result = []
        all_topn_result_idx = []

        if method == "identity" or method=="neutral_loss" or method=="hybrid":
            assert precursor_mz is not None, f"Precursor_mz is necessary for {method} search. This parameter should not be None."
        
                # Assign max_mz
        if precursor_ions_removal_da is not None and precursor_mz is not None:
            max_mz = precursor_mz - precursor_ions_removal_da

        else:
            max_mz = -1

        if clean:
            peaks = clean_spectrum(
                peaks=peaks,
                min_mz=0,
                max_mz=max_mz,
                noise_threshold=noise_threshold,
                min_ms2_difference_in_da=min_ms2_difference_in_da,
                max_peak_num=max_peak_num,
                normalize_intensity=True,
            )
            
        for group in range(len(self.group_start)):
            group_path = self.path_data / f"{group}"

            # Perform search
            if method == "identity":

                precursor_mz_file = group_path / "precursor_mz_array.bin"
                if precursor_mz_file.exists():
                    precursor_mz_array = np.memmap(precursor_mz_file, mode="r", dtype=np.float32)
                    spec_idx = np.where(abs(precursor_mz_array - precursor_mz) <= ms1_tolerance_in_da)[0]
                    
                    entropy_search=self._assign_entropy_search(group_path=group_path)

                    result = np.zeros(entropy_search.total_spectra_num, dtype=np.float32)
                    result[spec_idx] = entropy_search.search(method="open", peaks=peaks, ms2_tolerance_in_da=ms2_tolerance_in_da)[spec_idx]

                else:
                    raise RuntimeError("Precursor_mz_array not loaded. Call add_new_spectra(...) first. ")

            elif method == "open":

                entropy_search=self._assign_entropy_search(group_path=group_path)

                result = entropy_search.search(method="open", peaks=peaks, ms2_tolerance_in_da=ms2_tolerance_in_da)

            elif method == "neutral_loss":
                
                entropy_search=self._assign_entropy_search(group_path=group_path)

                result = entropy_search.search(method="neutral_loss", precursor_mz=precursor_mz, peaks=peaks, ms2_tolerance_in_da=ms2_tolerance_in_da)

            elif method == "hybrid":

                entropy_search=self._assign_entropy_search(group_path=group_path)
                                
                result = entropy_search.search_hybrid(precursor_mz=precursor_mz, peaks=peaks, ms2_tolerance_in_da=ms2_tolerance_in_da)
            
            else:
                raise ValueError(f"Unknown method: {method}. Use 'identity', 'open', 'neutral_loss' or 'hybrid'.")

            # Collect the results
            if topn is None:
                topn=len(result)
            else:
                topn=int(topn)
            topn = min(topn, len(result))
            topn_result_idx, topn_result = entropy_search.get_topn_spec_idx_and_similarity(similarity_array=result, topn=topn)

            # Get the global spec_idx
            topn_result_idx = [self.group_start[group] + idx for idx in topn_result_idx]

            # Combine the results
            all_topn_result.append(topn_result)
            all_topn_result_idx.append(topn_result_idx)

        # Sort and collect topn results
        all_result = np.concatenate(all_topn_result)
        all_result_idx = np.concatenate(all_topn_result_idx)

        collected_idx = np.argsort(all_result)[::-1][:topn]
        collected_result = all_result[collected_idx]
        collected_result_idx = all_result_idx[collected_idx].astype(np.uint64)

        output_result = []
        # Fetch metadata
        if need_metadata == True:
            for i, spec_idx in enumerate(collected_result_idx):
                spec_metadata = self[spec_idx]
                spec_metadata[f"{method}_search_entropy_similarity"] = collected_result[i]
                output_result.append(spec_metadata)

            return output_result

        else:
            # If need_metadata is False, return will be (global_spec_idx, final_result). There will be a consistent one-to-one match between these two elements.
            return list(zip(collected_result_idx, collected_result))

    def _assign_entropy_search(
            self,
            group_path:Path
    ):
        
        if (group_path/"information_dynamic.json").exists():
            entropy_search=self.entropy_search
            entropy_search.path_data=group_path
        elif (group_path/"information.json").exists():
            entropy_search = DynamicWithFlash(
                path_data=group_path, max_ms2_tolerance_in_da=self.max_ms2_tolerance_in_da, intensity_weight=self.intensity_weight
            )
        else:
            raise FileNotFoundError("Neither information.json nor information_dynamic.json exists. Failed to assign entropy search.")
        
        entropy_search.read()

        return entropy_search
        
    def convert_to_fast_search(
        self,
    ):
        # If this function is to be used, use it after `write()`.
        for group in range(len(self.group_start)):
            group_path = self.path_data / f"{group}"

            if (group_path/"information_dynamic.json").exists():
                self.entropy_search.path_data = group_path
                self.entropy_search.read()
                self.entropy_search.convert_to_fast_search()
                self.entropy_search.write()

        return

    def convert_current_index_to_flash(self):
        # Use this function after using `convert_to_fast_search()`
        flash_ions, flash_nl = self.entropy_search._extract_data_for_flash()
        dynamic_with_flash = DynamicWithFlash(
            path_data=self.entropy_search.path_data, max_ms2_tolerance_in_da=self.max_ms2_tolerance_in_da, intensity_weight=self.intensity_weight
        )

        dynamic_with_flash.total_peaks_num = self.entropy_search.total_peaks_num
        dynamic_with_flash.total_spectra_num = self.entropy_search.total_spectra_num
        dynamic_with_flash.max_ms2_tolerance_in_da = self.entropy_search.max_ms2_tolerance_in_da

        dynamic_with_flash.build_index(peak_data=flash_ions, max_indexed_mz=self.max_indexed_mz, peak_data_nl=flash_nl)
        self.entropy_search.remove_index()
        dynamic_with_flash.write()
        return
